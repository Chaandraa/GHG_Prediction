{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üåç Green House Gas Emission Prediction\n",
        "   ### **Description:** This project uses machine learning models to predict GHG emissions based on environmental data."
      ],
      "metadata": {
        "id": "O2Q3OsK6oxLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rsba8iBVPoH5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cMwCLULlohKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GrIjmZTFQ1Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1 : IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "etJu1KJyrjn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # data analysis\n",
        "import numpy as np  # used for numerical data\n",
        "import seaborn as sns # data visualization advance\n",
        "import matplotlib.pyplot as plt # basic data visualization (seaborn is made upon it)\n",
        "# MOTO: TORCHURE the data until it revels everything\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV # split the data\n",
        "from sklearn.preprocessing import StandardScaler #\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "import os"
      ],
      "metadata": {
        "id": "p869jL7CREer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2 : LOADING DATASET"
      ],
      "metadata": {
        "id": "KRTuxnTgqeFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "excel_file = '/content/drive/MyDrive/GHG/SupplyChainEmissionFactorsforUSIndustriesCommodities.xlsx'  # Replace with actual path\n",
        "years = range(2010, 2017)"
      ],
      "metadata": {
        "id": "6-SMcji8pu3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years[0]"
      ],
      "metadata": {
        "id": "2cdEVLSlqHEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_excel(excel_file, sheet_name=f'{years[0]}_Detail_Commodity')\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "pq9CsTU_qUSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = pd.read_excel(excel_file, sheet_name=f'{years[0]}_Detail_Industry')\n",
        "df_2.head()"
      ],
      "metadata": {
        "id": "5USsPPqqqvk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = [] #converting the dataframe into list format\n",
        "\n",
        "for year in years:\n",
        "    try:\n",
        "        df_com = pd.read_excel(excel_file, sheet_name=f'{year}_Detail_Commodity')\n",
        "        df_ind = pd.read_excel(excel_file, sheet_name=f'{year}_Detail_Industry')\n",
        "\n",
        "        #giving these columns a new name\n",
        "\n",
        "        df_com['Source'] = 'Commodity'\n",
        "        df_ind['Source'] = 'Industry'\n",
        "        df_com['Year'] = df_ind['Year'] = year\n",
        "\n",
        "        df_com.columns = df_com.columns.str.strip() #removing unnessesary indices\n",
        "        df_ind.columns = df_ind.columns.str.strip() #removing unnessesary indices\n",
        "\n",
        "        df_com.rename(columns={\n",
        "            'Commodity Code': 'Code',\n",
        "            'Commodity Name': 'Name'\n",
        "        }, inplace=True)\n",
        "\n",
        "        df_ind.rename(columns={\n",
        "            'Industry Code': 'Code',\n",
        "            'Industry Name': 'Name'\n",
        "        }, inplace=True)\n",
        "\n",
        "        all_data.append(pd.concat([df_com, df_ind], ignore_index=True))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing year {year}: {e}\")"
      ],
      "metadata": {
        "id": "F8d1XeotrBzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data[3]"
      ],
      "metadata": {
        "id": "xVWyOx1CrSeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_data)"
      ],
      "metadata": {
        "id": "zHsnpd3frbX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(all_data, ignore_index=True) #converting the list into dataframe and storing dta into new dataframe\n",
        "#using ignore_index=True to avoid index error that we get when we change list into df\n",
        "df.head()"
      ],
      "metadata": {
        "id": "hatOouHErpgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "nxz_2Vskrts1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3 : GETTING STARTED WITH DATA PREPROCESSING\n",
        "#### üîß Data Preprocessing: Preparing raw data for machine learning by cleaning, transforming, and organizing it."
      ],
      "metadata": {
        "id": "XuY2Yjy4wwih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#always the first step to read the columns how many columns are there\n",
        "df.columns"
      ],
      "metadata": {
        "id": "WQMdEADXrzOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for the null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "7MboKg_qsY97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As there is no data avaialble in Unnamed coulmn so we will drop the column\n",
        "df.drop(columns=['Unnamed: 7'],inplace=True)"
      ],
      "metadata": {
        "id": "MOQMofH4sdbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "EKz-7Xw4soUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())   # Checking data types and non-null counts"
      ],
      "metadata": {
        "id": "-02ZKXPMsrxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T # Checking summary statistics (important step for numerical data as it gives mean, min , max )"
      ],
      "metadata": {
        "id": "V-M8egS4swBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum() # Checking for null values in each column or any perticular column"
      ],
      "metadata": {
        "id": "NOz7YwsSs0Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize distribution\n",
        "sns.histplot(df['Supply Chain Emission Factors with Margins'], bins=50, kde=True)\n",
        "plt.title('Target Variable Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zu2RoDXSs4Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check categorical variables\n",
        "print(df['Substance'].value_counts())"
      ],
      "metadata": {
        "id": "gXzsUGcas8U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Unit'].value_counts()) # Checking unique values in 'Unit' with count"
      ],
      "metadata": {
        "id": "GBqQKO6HtCZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Unit'].unique()) # Checking unique values in 'Unit'"
      ],
      "metadata": {
        "id": "aNpSD9qSvifm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Source'].value_counts()) # Checking unique values in 'Source' with count"
      ],
      "metadata": {
        "id": "nw7LQI-FwCIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Substance'].unique() # Checking unique values in 'Substance'"
      ],
      "metadata": {
        "id": "Ub3R_lHOwGRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "substance_map={'carbon dioxide':0, 'methane':1, 'nitrous oxide':2, 'other GHGs':3} # Mapping substances to integers"
      ],
      "metadata": {
        "id": "FjXg7g3nwLId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Substance']=df['Substance'].map(substance_map)"
      ],
      "metadata": {
        "id": "E2GBrk84wPCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Substance'].unique() # Checking unique values in 'Substance'"
      ],
      "metadata": {
        "id": "Exq0aO3_wZ9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Unit'].unique()) # Checking unique values in 'Unit'"
      ],
      "metadata": {
        "id": "ojkKj9jNwdRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unit_map={'kg/2018 USD, purchaser price':0, 'kg CO2e/2018 USD, purchaser price':1} # Mapping units to integers"
      ],
      "metadata": {
        "id": "payFvy__whWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Unit']=df['Unit'].map(unit_map)"
      ],
      "metadata": {
        "id": "rmDn5gFbwucc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Unit'].unique()) # Checking unique values in 'Unit'"
      ],
      "metadata": {
        "id": "tmuSBcL7wx4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Source'].unique()) # Checking unique values in 'Source'"
      ],
      "metadata": {
        "id": "2PmiAvdLw3HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_map={'Commodity':0, 'Industry':1} # Mapping sources to integers"
      ],
      "metadata": {
        "id": "Xr2qqnjsw6xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Source']=df['Source'].map(source_map)   # applying the mapping to 'Source' column"
      ],
      "metadata": {
        "id": "38OxV5R3w-Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Source'].unique()) # Checking unique values in 'Source'"
      ],
      "metadata": {
        "id": "3E2gc79ExCkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() # Checking data types and non-null counts after mapping"
      ],
      "metadata": {
        "id": "YsduUuPIxkEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Code.unique() # Checking unique values in 'Code'"
      ],
      "metadata": {
        "id": "1vA5o41GxnS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Name.unique() # Checking unique values in 'Name'"
      ],
      "metadata": {
        "id": "jh3LZUVqxx3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.Name.unique()) # Checking number of unique values in 'Name'"
      ],
      "metadata": {
        "id": "Ggn7ntbux5km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_emitters = df[['Name', 'Supply Chain Emission Factors with Margins']].groupby('Name').mean().sort_values(\n",
        "    'Supply Chain Emission Factors with Margins', ascending=False).head(10)\n",
        "\n",
        "# Resetting index for better plotting\n",
        "top_emitters = top_emitters.reset_index()"
      ],
      "metadata": {
        "id": "-L_cdTBPyCFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_emitters"
      ],
      "metadata": {
        "id": "LwVs2hUVznaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the top 10 emitting industries\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "# Example: Top emitting industries (already grouped)\n",
        "sns.barplot(\n",
        "    x='Supply Chain Emission Factors with Margins',\n",
        "    y='Name',\n",
        "    data=top_emitters,\n",
        "    hue='Name',\n",
        "    palette='pastel'  # Use 'Blues', 'viridis', etc., for other color maps\n",
        ")\n",
        "\n",
        "# Add ranking labels (1, 2, 3...) next to bars\n",
        "for i, (value, name) in enumerate(zip(top_emitters['Supply Chain Emission Factors with Margins'], top_emitters.index), start=1):\n",
        "    plt.text(value + 0.01, i - 1, f'#{i}', va='center', fontsize=11, fontweight='bold', color='black')\n",
        "\n",
        "plt.title('Top 10 Emitting Industries', fontsize=14, fontweight='bold') # Title of the plot\n",
        "plt.xlabel('Emission Factor (kg CO2e/unit)') # X-axis label\n",
        "plt.ylabel('Industry') # Y-axis label\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6) # Adding grid lines for better readability\n",
        "plt.tight_layout() # Adjust layout to prevent overlap\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j4DaDOpfzrOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Name','Code','Year'], inplace=True)"
      ],
      "metadata": {
        "id": "yZxclScgzxEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "id": "2Lu2JYvA0CH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "HTk1UmSA0TPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Supply Chain Emission Factors with Margins']) # Feature set excluding the target variable\n",
        "y = df['Supply Chain Emission Factors with Margins'] # Target variable"
      ],
      "metadata": {
        "id": "b_YChCyH0XbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "FBGEERui0kZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "2Al0Srbu0n-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count plot for Substance\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.countplot(x=df[\"Substance\"])\n",
        "plt.title(\"Count Plot: Substance\")\n",
        "plt.xticks()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_jEF_wUO0woj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count plot for Unit\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.countplot(x=df[\"Unit\"])\n",
        "plt.title(\"Count Plot: Unit\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S2eJ-OMSeEOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count plot for Source\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=df[\"Source\"])\n",
        "plt.title(\"Count Plot: Source (Industry vs Commodity)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2v7i3Kz2rP0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "jDMqnHtJrUTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select_dtypes(include=np.number).corr() # Checking correlation between numerical features"
      ],
      "metadata": {
        "id": "HJgISiSyrZcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() # Checking data types and non-null counts after mapping"
      ],
      "metadata": {
        "id": "_lYxzFGBrhsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "#getting a better understanding on which column is interrelated to which\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IckNnpKsrlSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe().T"
      ],
      "metadata": {
        "id": "U9lVLc4RroiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features\n",
        "scaler = StandardScaler() #standardize data\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "v3CVDD1MrsyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dividing the data into train and test models"
      ],
      "metadata": {
        "id": "4LatFt3JAkRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42) # Splitting data into training and testing sets"
      ],
      "metadata": {
        "id": "wjIfdN6ur8gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled[0].min(),X_scaled[0].max()"
      ],
      "metadata": {
        "id": "505wRK-Hrvix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(X_scaled.mean()),np.round(X_scaled.std())"
      ],
      "metadata": {
        "id": "IZQ27uxqrzOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "H0vCczsHr2kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "e70kVjMrsBek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "JrPgio6msFtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_model = RandomForestRegressor(random_state=42) # Initializing Random Forest Regressor"
      ],
      "metadata": {
        "id": "UwafW03dsJH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_model.fit(X_train, y_train) # Fitting the model on training data"
      ],
      "metadata": {
        "id": "POPE_WhMsPAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_y_pred = RF_model.predict(X_test) # Making predictions on the test set"
      ],
      "metadata": {
        "id": "3vypoa0wsSaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_y_pred[:20]"
      ],
      "metadata": {
        "id": "qVtKp52ps3PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_mse = mean_squared_error(y_test, RF_y_pred) # Calculating Mean Squared Error (MSE)\n",
        "RF_rmse = np.sqrt(RF_mse) # Calculating Root Mean Squared Error (RMSE)\n",
        "# Calculating R¬≤ score\n",
        "RF_r2 = r2_score(y_test, RF_y_pred)\n",
        "\n",
        "print(f'RMSE: {RF_rmse}')\n",
        "print(f'R¬≤ Score: {RF_r2}')"
      ],
      "metadata": {
        "id": "aAPIYOnos54b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression # Importing Linear Regression model\n",
        "LR_model = LinearRegression() # Initializing Linear Regression model\n",
        "# Fitting the Linear Regression model on training data\n",
        "\n",
        "LR_model.fit(X_train, y_train)\n",
        "\n",
        "LR_y_pred = LR_model.predict(X_test) # Making predictions on the test set using Linear Regression model\n",
        "\n",
        "\n",
        "LR_mse = mean_squared_error(y_test, LR_y_pred) # Calculating Mean Squared Error (MSE) for Linear Regression model\n",
        "LR_rmse = np.sqrt(LR_mse) # Calculating Root Mean Squared Error (RMSE) for Linear Regression model\n",
        "LR_r2 = r2_score(y_test, LR_y_pred) # Calculating R¬≤ score for Linear Regression model\n",
        "\n",
        "print(f'RMSE: {LR_rmse}')\n",
        "print(f'R¬≤ Score: {LR_r2}')"
      ],
      "metadata": {
        "id": "PwDgQv4ms8vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction evaluation"
      ],
      "metadata": {
        "id": "KI1DrmcyG4bX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "FLUpG01mHn4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Random Forest Regressor using GridSearchCV\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation to find the best hyperparameters\n",
        "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search model on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model from grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "id": "CzkMlRV0tAbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best model to make predictions on the test set\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "\n",
        "HP_mse = mean_squared_error(y_test, y_pred_best)\n",
        "HP_rmse = np.sqrt(HP_mse)\n",
        "HP_r2 = r2_score(y_test, y_pred_best)\n",
        "\n",
        "print(f'RMSE: {HP_rmse}')\n",
        "print(f'R¬≤ Score: {HP_r2}')\n"
      ],
      "metadata": {
        "id": "_FW2aZGFtEG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Comapartive Study and Selecting the Best model"
      ],
      "metadata": {
        "id": "pqJTDrM0SMko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a comparative DataFrame for all models\n",
        "results = {\n",
        "    'Model': ['Random Forest (Default)', 'Linear Regression', 'Random Forest (Tuned)'],\n",
        "    'MSE': [RF_mse, LR_mse, HP_mse],\n",
        "    'RMSE': [RF_rmse, LR_rmse, HP_rmse],\n",
        "    'R2': [RF_r2, LR_r2, HP_r2]\n",
        "}\n",
        "\n",
        "# Create a DataFrame to compare the results of different models\n",
        "comparison_df = pd.DataFrame(results)\n",
        "print(comparison_df)"
      ],
      "metadata": {
        "id": "09CS6m7auNX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to save the models if it doesn't exist\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "7BXaupLkupwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model and encoders\n",
        "joblib.dump(best_model, 'models/LR_model.pkl')    # Save the best model\n",
        "joblib.dump(scaler, 'models/scaler.pkl') # Save the scaler used for normalization\n"
      ],
      "metadata": {
        "id": "wwZFzCiEutTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "yF5s2O4AvO_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Week 2: Greenhouse Gas Emission Prediction (tasks done)\n",
        "\n",
        "## Step 1: Importing Required Libraries\n",
        "\n",
        "## Step 2: Loading the Dataset\n",
        "\n",
        "## Step 3: Data Preprocessing (EDA, Cleaning, Encoding)\n",
        "\n",
        "## Step 4: Model Training\n",
        "- Linear Regression\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "\n",
        "## Step 5: Model Evaluation\n",
        "- RMSE, MAE, R¬≤ Score\n",
        "\n",
        "## Step 6: Hyperparameter Tuning with GridSearchCV\n",
        "- Random Forest tuning results\n",
        "\n",
        "## Step 7: Visualization\n",
        "- Performance Comparison\n",
        "- Residual Plots\n",
        "- Feature Importance\n",
        "\n",
        "## Step 8: Saving the Best Model\n",
        "\n",
        "## Step 9: Conclusion and Insights\n"
      ],
      "metadata": {
        "id": "34YmZ8bRUyme"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0siZs2sDVBkT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}